{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CliNER 2.0: Accessible and Accurate Clinical Concept Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ClinicalNER import clinicalNER\n",
    "NER = clinicalNER()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data/origin/CoNLL.train.\n"
     ]
    }
   ],
   "source": [
    "train_txt_path = \"data/converted/CoNLL_train.txt\"\n",
    "train_con_path = \"data/converted/CoNLL_train.con\"\n",
    "NER.read_dataset(\"data/origin/CoNLL.train\", train_txt_path, train_con_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data/origin/CoNLL_small.test.\n"
     ]
    }
   ],
   "source": [
    "test_txt_path = \"data/converted/CoNLL_test.txt\"\n",
    "test_con_path = \"data/converted/CoNLL_test.con\"\n",
    "NER.read_dataset(\"data/origin/CoNLL_small.test\", test_txt_path, test_con_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DEV\n",
      "\tCreating 90/10 train/dev split\n",
      "\tvectorizing words all\n",
      "\ttraining classifiers all\n",
      "\n",
      "serializing model to models/CoNLL.model\n",
      "\n",
      "<ipykernel.iostream.OutStream object at 0x10be7d7b8>\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "model    : /Users/Candy/Desktop/ditk/extraction/named_entity/ClinicalNER/code/models/CoNLL.model\n",
      "\n",
      "modeltype: CRF\n",
      "\tGENIA     : False\n",
      "\tUMLS      : False\n",
      "\n",
      "\tfeatures  : Generic#         NEXT*            PREV*            dummy            \n",
      "\t            last_two_letters length           metric_unit      mitre            \n",
      "\t            pos              stem_lancaster   stem_porter      word             \n",
      "\t            word_shape       \n",
      "\n",
      "\n",
      "training began: 2019-05-01 05:08:07\n",
      "training ended: 2019-05-01 06:44:46\n",
      "\n",
      "scores\n",
      "\ttrain precision:   1.000  0.998  0.999  0.995  1.000  0.999  1.000\n",
      "  0.999  0.998\n",
      "\ttrain recall   :   1.000  0.997  0.998  0.997  0.995  0.998  1.000\n",
      "  0.998  0.999\n",
      "\ttrain f1       :   1.000  0.998  0.999  0.996  0.997  0.999  1.000\n",
      "  0.998  0.999\n",
      "\n",
      "\n",
      "train\n",
      "         0    1    2    3    4    5    6    7    8  (gold)\n",
      " 0    153701    9    3   10   11    0    0    7    0 \n",
      " 1       2 6437    1    7    1    0    0    0    0 \n",
      " 2       1    0 5923    3    0    0    0    0    0 \n",
      " 3       8    9    9 5705    1    0    0    0    1 \n",
      " 4       1    0    0    0 3105    0    0    0    0 \n",
      " 5       0    1    0    0    0 1056    0    0    0 \n",
      " 6       0    1    0    0    0    0 4057    0    0 \n",
      " 7       2    0    0    0    0    2    0 3358    0 \n",
      " 8       0    0    0    0    2    0    0    0 1065 \n",
      "(pred)\n",
      "\n",
      "\n",
      "\tdev precision   :   0.975  0.937  0.930  0.898  0.923  0.918  0.954\n",
      "  0.848  0.827\n",
      "\tdev recall      :   0.995  0.877  0.839  0.752  0.755  0.677  0.919\n",
      "  0.755  0.697\n",
      "\tdev f1          :   0.985  0.906  0.882  0.818  0.830  0.779  0.936\n",
      "  0.799  0.756\n",
      "\n",
      "\n",
      "dev\n",
      "         0    1    2    3    4    5    6    7    8  (gold)\n",
      " 0    16732   56   72  105   63   23   29   64   23 \n",
      " 1       8  599   10   14    1    1    0    6    0 \n",
      " 2      14    7  557   14    4    0    1    2    0 \n",
      " 3      16   13   13  448    7    0    0    1    1 \n",
      " 4       3    4    2    9  240    0    0    1    1 \n",
      " 5       2    1    0    0    0   67    0    3    0 \n",
      " 6       5    1    7    2    1    2  433    3    0 \n",
      " 7      24    2    3    4    1    3    7  256    2 \n",
      " 8       5    0    0    0    1    3    1    3   62 \n",
      "(pred)\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Training Completed.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/CoNLL.model\"\n",
    "NER.train(train_txt_path, train_con_path, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWARNING: prediction file already exists (data/test_predictions/CoNLL_test.con)\n",
      "------------------------------\n",
      "\n",
      "\t1 of 1\n",
      "\tdata/converted/CoNLL_test.txt\n",
      "\n",
      "\tvectorizing words all\n",
      "\tpredicting  labels all\n",
      "\n",
      "\n",
      "writing to: data/test_predictions/CoNLL_test.con\n",
      "\n",
      "Prediction Completed.\n"
     ]
    }
   ],
   "source": [
    "prediction_dir = \"data/test_predictions/\"\n",
    "model_path = \"models/CoNLL.model\"\n",
    "prediction_path = NER.predict(model_path, test_txt_path, prediction_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.970873786407767\n",
      "Recall:  0.8695652173913043\n",
      "F1 Score:  0.9174311926605504\n",
      "Evaluation Completed.\n"
     ]
    }
   ],
   "source": [
    "NER.evaluate(prediction_path, test_con_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the predictions to the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write to output files.\n"
     ]
    }
   ],
   "source": [
    "output_path = \"data/output/CoNLL_test.output\"\n",
    "NER.output(test_txt_path, test_con_path, prediction_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
