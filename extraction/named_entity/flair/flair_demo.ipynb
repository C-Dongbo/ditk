{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "from main import FlairClass \n",
    "from flair.data_fetcher import  NLPTaskDataFetcher, NLPTask\n",
    "\n",
    "print (\"import done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created : <main.FlairClass object at 0x1a278c2978>\n"
     ]
    }
   ],
   "source": [
    "flair_obj = FlairClass()\n",
    "print (\"Created :\", flairClass_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-01 00:36:54,551 Reading data from resources/tasks/conll_03\n",
      "2019-05-01 00:36:54,553 Train: resources/tasks/conll_03/eng.train\n",
      "2019-05-01 00:36:54,554 Dev: resources/tasks/conll_03/eng.testa\n",
      "2019-05-01 00:36:54,554 Test: resources/tasks/conll_03/eng.testb\n",
      "2019-05-01 00:39:34,246 this function is deprecated, use smart_open.open instead\n",
      "Reading done\n"
     ]
    }
   ],
   "source": [
    "# Build path to input files\n",
    "file_dict = {}\n",
    "file_dict['base_path'] = 'resources/tasks'\n",
    "\n",
    "# Read the data\n",
    "flair_obj.read_dataset(file_dict, NLPTask.CONLL_03)\n",
    "\n",
    "print (\"Reading done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-30 20:23:36,766 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-30 20:23:36,768 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-30 20:23:36,777 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-04-30 20:23:52,588 epoch 1 - iter 0/469 - loss 48.20370483\n",
      "2019-04-30 20:35:00,458 epoch 1 - iter 46/469 - loss 8.88953011\n",
      "2019-04-30 20:46:39,033 epoch 1 - iter 92/469 - loss 6.23656634\n",
      "2019-04-30 20:58:59,532 epoch 1 - iter 138/469 - loss 5.11600468\n",
      "2019-04-30 21:09:08,043 epoch 1 - iter 184/469 - loss 4.42367249\n",
      "2019-04-30 21:20:20,807 epoch 1 - iter 230/469 - loss 3.98254336\n",
      "2019-04-30 21:32:21,678 epoch 1 - iter 276/469 - loss 3.64331063\n",
      "2019-04-30 21:45:06,826 epoch 1 - iter 322/469 - loss 3.37539084\n",
      "2019-04-30 22:00:24,238 epoch 1 - iter 368/469 - loss 3.16289599\n",
      "2019-04-30 22:15:50,243 epoch 1 - iter 414/469 - loss 3.01342118\n",
      "2019-04-30 22:30:28,449 epoch 1 - iter 460/469 - loss 2.85689926\n",
      "2019-04-30 22:32:57,888 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-30 22:32:57,893 EPOCH 1 done: loss 2.8433 - lr 0.1000 - bad epochs 0\n",
      "2019-04-30 22:51:28,246 DEV  : loss 1.07601261 - f-score 0.8982 - acc 0.8152\n",
      "2019-04-30 23:10:30,677 TEST : loss 1.17560339 - f-score 0.8626 - acc 0.7585\n",
      "2019-04-30 23:11:19,601 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-30 23:11:19,617 Testing using best model ...\n",
      "2019-04-30 23:11:19,634 loading file resources/taggers/example-ner/best-model.pt\n",
      "2019-04-30 23:16:03,731 MICRO_AVG: acc 0.7561 - f1-score 0.8611\n",
      "2019-04-30 23:16:03,761 MACRO_AVG: acc 0.7403 - f1-score 0.8457\n",
      "2019-04-30 23:16:03,763 LOC        tp: 1534 - fp: 346 - fn: 134 - tn: 1534 - precision: 0.8160 - recall: 0.9197 - accuracy: 0.7617 - f1-score: 0.8648\n",
      "2019-04-30 23:16:03,765 MISC       tp: 548 - fp: 212 - fn: 154 - tn: 548 - precision: 0.7211 - recall: 0.7806 - accuracy: 0.5996 - f1-score: 0.7497\n",
      "2019-04-30 23:16:03,766 ORG        tp: 1315 - fp: 265 - fn: 346 - tn: 1315 - precision: 0.8323 - recall: 0.7917 - accuracy: 0.6828 - f1-score: 0.8115\n",
      "2019-04-30 23:16:03,768 PER        tp: 1553 - fp: 76 - fn: 64 - tn: 1553 - precision: 0.9533 - recall: 0.9604 - accuracy: 0.9173 - f1-score: 0.9568\n",
      "2019-04-30 23:16:03,769 ----------------------------------------------------------------------------------------------------\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "# Train the model. Data is already read and stored in instance variables of flair_obj\n",
    "# Send the number of epochs as a keyword argument\n",
    "flair_obj.train(None, epochs=1)\n",
    "\n",
    "print (\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-01 00:39:44,607 loading file /Users/anuragkakati/.flair/models/en-ner-conll03-v0.4.pt\n",
      "George <B-PER> Washington <E-PER> went to Washington <S-LOC> .\n",
      "Barack <B-PER> Obama <E-PER> was a very good president of USA <S-LOC> .\n",
      "Output written to file : flair_predict_output.txt\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on data from file 'predict_data_file'\n",
    "with open('flair_predict_input.txt', 'r') as predict_file_p:\n",
    "    predictions = flair_obj.predict(predict_file_p)\n",
    "\n",
    "for each_prediction in predictions:\n",
    "    print (each_prediction.strip())\n",
    "\n",
    "output_file_path = 'flair_predict_output.txt'\n",
    "# Write the predictions to a file\n",
    "with open(output_file_path, 'w') as predict_output_file_p:\n",
    "    for each_predictions in predictions:\n",
    "        predict_output_file_p.write(each_predictions)\n",
    "\n",
    "print (\"Output written to file : {}\".format(output_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FlairClass' object has no attribute 'evaluations'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-816e38be8224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflair_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final F1 score :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/USC_Study/2nd_Sem/CS548/Project/Phase 2/ditk/extraction/named_entity/flair/main.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, predictions, groundTruths, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \"\"\"\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mevaluations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mevaluations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FlairClass' object has no attribute 'evaluations'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Run Evaluation\n",
    "evaluations = flair_obj.evaluate(predictions, None)\n",
    "print(\"Final F1 score :\", evaluations[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
